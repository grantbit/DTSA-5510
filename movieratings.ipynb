{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['movies.dat', 'ratings.dat', 'users.dat']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "zip_file_path = 'archive.zip'\n",
    "extract_to_dir = 'MovieLens'\n",
    "os.makedirs(extract_to_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    for file_name in ['movies.dat', 'ratings.dat', 'users.dat']:\n",
    "        zip_ref.extract(file_name, extract_to_dir)\n",
    "\n",
    "extracted_files = os.listdir(extract_to_dir)\n",
    "print(f\"Extracted files: {extracted_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies DataFrame:\n",
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "\n",
      "Ratings DataFrame:\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "\n",
      "Users DataFrame:\n",
      "   UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n"
     ]
    }
   ],
   "source": [
    "movies_file = os.path.join(extract_to_dir, 'movies.dat')\n",
    "ratings_file = os.path.join(extract_to_dir, 'ratings.dat')\n",
    "users_file = os.path.join(extract_to_dir, 'users.dat')\n",
    "\n",
    "# Define the column names based on the data format\n",
    "movies_columns = ['MovieID', 'Title', 'Genres']\n",
    "ratings_columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "users_columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    "\n",
    "# Load the data into pandas DataFrames \n",
    "movies_df = pd.read_csv(movies_file, sep='::', header=None, names=movies_columns, engine='python', encoding='ISO-8859-1')\n",
    "ratings_df = pd.read_csv(ratings_file, sep='::', header=None, names=ratings_columns, engine='python', encoding='ISO-8859-1')\n",
    "users_df = pd.read_csv(users_file, sep='::', header=None, names=users_columns, engine='python', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows of each DataFrame to confirm the data is loaded correctly\n",
    "print(\"Movies DataFrame:\")\n",
    "print(movies_df.head())\n",
    "\n",
    "print(\"\\nRatings DataFrame:\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "print(\"\\nUsers DataFrame:\")\n",
    "print(users_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = ratings_df.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "# Fill missing values with zeros for the initial matrix\n",
    "user_item_matrix_filled = user_item_matrix.fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create user-item matrices for training and testing sets\n",
    "train_matrix = train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "test_matrix = test_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py:1759: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for the test set: 2.7411791762164253\n"
     ]
    }
   ],
   "source": [
    "# Apply NMF\n",
    "nmf_model = NMF(n_components=20, init='random', random_state=42)\n",
    "W = nmf_model.fit_transform(train_matrix)\n",
    "H = nmf_model.components_\n",
    "\n",
    "# Predict the ratings\n",
    "predicted_ratings = np.dot(W, H)\n",
    "\n",
    "# Ensure the predicted ratings are in the same shape as the original user-item matrix\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings, index=train_matrix.index, columns=train_matrix.columns)\n",
    "\n",
    "# Function to compute RMSE\n",
    "def compute_rmse(actual, predicted):\n",
    "    # Flatten the matrices\n",
    "    actual = actual.values.flatten()\n",
    "    predicted = predicted.values.flatten()\n",
    "    # Filter out zero values\n",
    "    mask = actual > 0\n",
    "    actual = actual[mask]\n",
    "    predicted = predicted[mask]\n",
    "    # Compute RMSE\n",
    "    rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "    return rmse\n",
    "\n",
    "# Compute RMSE for the test set\n",
    "test_user_item_matrix = test_matrix.reindex(index=predicted_ratings_df.index, columns=predicted_ratings_df.columns).fillna(0)\n",
    "rmse = compute_rmse(test_user_item_matrix, predicted_ratings_df)\n",
    "\n",
    "print(f\"RMSE for the test set: {rmse}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE of 2.741 for the NMF model on the test set indicates a significant prediction error. Given that movie ratings typically range from 1 to 5, this high RMSE suggests that the model's predictions are not very accurate. This outcome can be attributed to the sparsity of the dataset, where most users have rated only a small fraction of the available movies. Sparse matrices pose a challenge for NMF, as it tries to learn latent features from limited data. Additionally, biases in the data, such as users tending to rate movies they feel strongly about, may not be well captured by the NMF model, leading to less accurate predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison, simpler baseline methods like predicting the global average rating or a user's average rating can sometimes perform better because they capture the central tendency of the ratings. Similarity-based methods, such as k-Nearest Neighbors, often outperform matrix factorization in sparse settings by leveraging user-user or item-item similarities. To improve the NMF model's performance, one could consider hybrid models that combine NMF with similarity-based methods, data augmentation to reduce sparsity, regularization techniques to prevent overfitting, or exploring more advanced matrix factorization techniques like SVD or ALS. Incorporating additional data sources, such as user demographics or movie metadata, could also enhance the model's predictive power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
